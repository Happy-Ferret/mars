{"name":"MARS","tagline":"Asynchronous Block-Level Storage Replication","body":"# MARS = Multiversion Asynchronous Replicated Storage\r\n\r\n![MARS Logo](docu/images/earth-mars-transfer.jpg)\r\n\r\n`git clone git@github.com:schoebel/mars.git`\r\n\r\nor https://github.com/schoebel/mars\r\n\r\nGPLed software AS IS, sponsored by 1&1 Internet AG (www.1und1.de). Contact: tst@1und1.de\r\n\r\n## What is MARS Light?\r\n\r\nMARS can be used to replicate Linux-based storage devices, or even whole datacenters, over arbitrary distances (geo-redundancy).\r\n\r\nMain features:\r\n* Anytime Consistency\r\n* Arbitrary Distances\r\n* Tolerates Flaky Networks\r\n\r\nMARS Light is almost a drop-in replacement for DRBD (block-level storage replication). It runs as a Linux kernel module.\r\n\r\nIn contrast to plain DRBD, it works _asynchronously_ and over\r\narbitrary distances. Our internal 1&1 testing runs between datacenters\r\nin the US and Europe. MARS uses very different technology under the\r\nhood, similar to transaction logging of database systems.\r\n\r\nReliability: application and replication are completely decoupled.\r\nNetworking problems (e.g. packet loss, bottlenecks) have no\r\nimpact onto your application at the primary side.\r\n\r\nAnytime Consistency: on a secondary node, its version of the underlying\r\ndisk device is always consistent in itself, but may be outdated\r\n(represent a former state from the primary side). Thanks to\r\nincremental replication of the transaction logfiles, usually the\r\nlag-behind will be only a few seconds, or parts of a second.\r\n\r\nSynchronous or near-synchronous operating modes are planned for\r\nthe future, but are expected to work _reliably_ only over short \r\ndistances (less than 50km), due to fundamental properties\r\nof distributed systems.\r\n\r\nWARNING! Current stage is BETA. It has been already tested with productive data, but there is no guarantee (as with any GPL software).\r\n\r\n## Documentation / Manual\r\n\r\nSee https://github.com/schoebel/mars/blob/master/docu/mars-manual.pdf\r\n\r\nIntro: the use cases MARS vs DRBD can be found in chapter 1.\r\n\r\n## Concepts\r\n\r\nFor a very short intro, see my LCA2013 presentation https://github.com/schoebel/mars/blob/master/docu/MARS_LCA2013.pdf .\r\n\r\nThere is also an internal 2-years old concept paper which is so much outdated,\r\nthat I don't want to publish it. \r\n\r\nThe fundamental construction principle of the planned MARS Full\r\nis called Instance Oriented Programming (IOP) and is described in\r\nthe following paper:\r\n\r\nhttp://athomux.net/papers/paper_inst2.pdf\r\n\r\n## History\r\n\r\nAs you can see in the git log, it evolved from a very experimental\r\nconcept study, starting in the Summer of 2010.\r\nAt that time, I was working on it in my spare time.\r\n\r\nIn Summer 2011, an \"official\" internal 1&1 project started, which aimed\r\nto deliver a proof of concept.\r\n\r\nIn February 2012, a pilot system was rolled out to an internal statistics\r\nserver, which collects statistics data from thousands of other servers,\r\nand thus produces a very heavy random-access write load, formerly\r\nreplicated with DRBD (which led to performance problems due to massive\r\nrandomness). After switching to MARS, the performance was provably\r\nbetter.\r\n\r\nAfter curing some small infancy problems, that server runs until today\r\nwithout problems. It was upgraded to newer versions of MARS several\r\ntimes (indicated by some of the git tags). Our sysadmins switched the\r\nprimary side a few times, without informing me, so I could\r\nsleep better at night without knowing what they did ;)\r\n\r\nIn Summer 2012, the next \"official\" internal 1&1 project started. Its goal\r\nwas to reach enterprise grade, and therefore to rollout MARS Light on\r\n~15 productive servers, starting with less critical systems like ones\r\nfor test webspaces etc.\r\n\r\nIn December 2012 (shortly before Christmas), I got the official permission\r\nfrom our CTO Henning Kettler to publish MARS under GPL on github. Many thanks to him!\r\n\r\nBefore that point, I was bound to my working contract which kept internal\r\nsoftware as secret by default (when there was no explicit permission).\r\n\r\nNow there is a chance to build up an opensource\r\ncommunity for MARS, partially outside of 1&1.\r\n\r\nI will also try to respect the guidelines from Linus, but probably this\r\nwill need more work. I am already planning to invest some time into\r\ncommunity revision of the sourcecode, but there is not yet any schedule.\r\n\r\nIn May 2013, I got help by my new collegue Frank Liepold. He is working\r\non a fully automatic test suite which automates regression tests\r\n(goal: rolling releases). That test suite is based on the internal\r\ntest suite of blkreplay and can be found in the test_suite/ subdirectory.\r\n\r\nIn November 2013, internal 1&1 projects started for mass rollout to several thousands of servers.\r\n\r\nAlthough the software continues to be labelled \"beta\" for the next future, it has reached enterprise grade due to our internal rating process.\r\n\r\n## Future Plans / Roadmap\r\n\r\nSmaller Reworks: in Winter 2013/2014, some smaller changes to the symlink tree are planned, in order to make it more readable for humans and to prepare for future enhancements. They will only change the syntax, not the semantics. There will be an upgrade plan, i.e. the old symlink tree remains usable; only newly created clusters will use the new structure.\r\n\r\nIn parallel, the software will be internally divided into three parts:\r\n\r\n1. Generic brick framework\r\n2. AIO personality with XIO bricks\r\n3. MARS Light application\r\n\r\nI hope this will make MARS more attractive for the mainline Linux kernel community. When everything runs fine, the upstream code revision could start in Spring 2014.\r\n\r\nMARS FULL is planned in the following steps:\r\n\r\n1. MARS FULL infrastructure, IOP replacement for the ad-hoc Light instantiation logic, functionally equivalent (regression testing with Frank's test suite).\r\n2. Remote device. `/dev/mars/mydata` can appear anywhere in a cluster, independently from primary switching. Estimated release date: end of 2014.\r\n3. Virtual point-in-time restore. Creates a read-only snapshot on-the-fly, for any unplanned time in the past, with second resolution. Estimated release date: end of 2015.\r\n\r\nFurther MARS FULL features are possible, but there is no schedule yet.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}